import joblib
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

# === Modell laden ===
obj = joblib.load("rf_dashboard.joblib")

# Falls das gespeicherte Objekt ein Dictionary ist
if isinstance(obj, dict):
    # Modell aus h√§ufigen Keys extrahieren
    for key in ["model", "rf", "random_forest", "estimator"]:
        if key in obj:
            rf = obj[key]
            break
else:
    rf = obj

# === Einen Beispielbaum ausw√§hlen ===
tree = rf.estimators_[0]   # erster Baum

# === Feature-Namen laden oder Dummy-Namen erzeugen ===
if hasattr(rf, "feature_names_in_"):
    feature_names = rf.feature_names_in_
else:
    feature_names = [f"Feature_{i}" for i in range(rf.n_features_in_)]

# === Baum visualisieren ===
plt.figure(figsize=(22, 12))

# max_depth begrenzt die Darstellung, damit es nicht zu gro√ü wird
plot_tree(
    tree,
    feature_names=feature_names,
    filled=True,
    max_depth=3        # <<< Du kannst auch 4 oder 5 probieren
)

plt.title("Beispielbaum aus dem Random Forest (max_depth=3)")
plt.show()













import io
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st
import joblib
import shap
import plotly.express as px

# ------------------------------------------------------------------
# 0. Grund-Setup
# ------------------------------------------------------------------

st.set_page_config(
    page_title="KM9 KI-Dashboard ‚Äì Analyse / Replay",
    layout="wide"
)

st.title("KM9 KI-Dashboard ‚Äì Analyse / Replay Modus")
st.caption("Vorhersage, Vergleich und Erkl√§rbarkeit historischer Fahrten (HMI-√§hnlich, reduziert gehalten).")


# ------------------------------------------------------------------
# 1. Modell laden
# ------------------------------------------------------------------

MODEL_PATH = "rf_dashboard.joblib"

@st.cache_resource(show_spinner="Lade Random-Forest-Modell...")
def load_model_bundle(path: str):
    bundle = joblib.load(path)
    return bundle

bundle = load_model_bundle(MODEL_PATH)
model = bundle["model"]
feature_names = bundle["feature_names"]
target_name = bundle["target_name"]
trained_at = bundle.get("trained_at", "unbekannt")
base_metrics = bundle.get("metrics", {})

st.sidebar.subheader("Modell-Info")
st.sidebar.write(f"**Trainiert am:** {trained_at}")
st.sidebar.write(f"**Zielgr√∂√üe:** `{target_name}`")
st.sidebar.write(
    f"**R¬≤ (Trainingseval):** {base_metrics.get('r2', float('nan')):.3f}  "
    f"/ **MAE:** {base_metrics.get('mae', float('nan')):.4f}"
)


# ------------------------------------------------------------------
# 2. CSV Upload & Vorbereitung
# ------------------------------------------------------------------

st.sidebar.subheader("Replay-Konfiguration")

uploaded_file = st.sidebar.file_uploader(
    "Historische CSV-Datei w√§hlen",
    type=["csv"],
    help="CSV in gleicher Feature-Struktur wie beim Modelltraining."
)

# Der Nutzer kann Ziel- und Zeitspalte anpassen
target_col = st.sidebar.text_input(
    "Zielspalte (Dicke, Ist-Wert)",
    value=target_name,
    help="Spaltenname mit der gemessenen Dicke im CSV."
)

time_col = st.sidebar.text_input(
    "Zeitspalte (optional)",
    value="timestamp",
    help="Zeitstempel-Spalte, falls vorhanden (wird zur Sortierung und Anzeige genutzt)."
)

# Fenstergr√∂√üe f√ºr den ‚Äûabgespielten‚Äú Ausschnitt
window_size = st.sidebar.slider(
    "Anzeigefenster (Anzahl Punkte im Verlauf)",
    min_value=100,
    max_value=5000,
    value=1000,
    step=100,
    help="Wie viele Messpunkte sollen im Zeitverlauf gleichzeitig angezeigt werden?"
)

# ------------------------------------------------------------------
# 2.1 Daten + Vorhersagen vorbereiten (gecached)
# ------------------------------------------------------------------

@st.cache_data(show_spinner="Bereite CSV und Modellvorhersagen vor...")
def prepare_replay_data(file_bytes: bytes, target_col: str, time_col: str, feature_names: list):
    # CSV einlesen
    df_raw = pd.read_csv(io.BytesIO(file_bytes))

    # Zeitspalte parsen & sortieren (falls vorhanden)
    if time_col in df_raw.columns:
        df_raw[time_col] = pd.to_datetime(df_raw[time_col], errors="coerce")
        df_raw = df_raw.sort_values(time_col).reset_index(drop=True)
    else:
        # Falls keine Zeitspalte vorhanden, Index als ‚ÄûZeit‚Äú verwenden
        df_raw = df_raw.reset_index(drop=True)
        df_raw["__index_as_time__"] = df_raw.index

    # Check: Zielspalte vorhanden?
    if target_col not in df_raw.columns:
        raise ValueError(
            f"Zielspalte '{target_col}' nicht im CSV gefunden. "
            f"Gefundene Spalten: {list(df_raw.columns)[:15]} ..."
        )

    # Check: Feature-Spalten
    missing_features = [f for f in feature_names if f not in df_raw.columns]
    if missing_features:
        raise ValueError(
            "Folgende Modell-Features fehlen im CSV (Feature-Engineering identisch?): "
            + ", ".join(missing_features[:20])
        )

    # Feature-Matrix X und Ziel y aufbauen
    X = df_raw[feature_names].copy()
    y_true = df_raw[target_col].copy()

    # Modellvorhersage
    y_pred = model.predict(X)

    # Ergebnis-DF f√ºr Replay
    if time_col in df_raw.columns:
        df_res = df_raw[[time_col]].copy()
        df_res.rename(columns={time_col: "time"}, inplace=True)
    else:
        df_res = df_raw[["__index_as_time__"]].copy()
        df_res.rename(columns={"__index_as_time__": "time"}, inplace=True)

    df_res["y_true"] = y_true
    df_res["y_pred"] = y_pred
    df_res["error"] = df_res["y_true"] - df_res["y_pred"]

    return df_res, X


# ------------------------------------------------------------------
# 3. Hauptlogik: nur wenn eine CSV geladen wurde
# ------------------------------------------------------------------

if uploaded_file is None:
    st.info("Bitte links im Sidebar eine historische CSV-Datei ausw√§hlen, um den Replay-Modus zu starten.")
    st.stop()

try:
    csv_bytes = uploaded_file.getvalue()
    df_res, X_features = prepare_replay_data(csv_bytes, target_col, time_col, feature_names)
except Exception as e:
    st.error(f"Fehler bei der Vorbereitung der Daten: {e}")
    st.stop()

n_points = len(df_res)
st.markdown(f"**Geladene Fahrt:** {n_points} Messpunkte")

# ------------------------------------------------------------------
# 4. Replay-‚ÄûPosition‚Äú (Zeitachse / Simulation des Live-Betriebs)
# ------------------------------------------------------------------

st.sidebar.subheader("Replay-Steuerung")

# Replay-Index im Session-State halten (damit Buttons funktionieren)
if "replay_index" not in st.session_state:
    # Starte am Anfang der Fahrt
    st.session_state.replay_index = 0

# Fall A: Zu wenige Punkte -> kein Slider / keine Buttons n√∂tig
if n_points <= 1:
    st.sidebar.info(
        f"Die geladene Fahrt enth√§lt nur {n_points} Messpunkt(e). "
        "Der Replay-Slider ist daher deaktiviert."
    )
    replay_index = 0

# Fall B: Normale Fahrt -> Simulation wie Live-Daten
else:
    # Batch-Gr√∂√üe ausw√§hlbar machen (z.B. 500 Zeilen)
    batch_size = st.sidebar.selectbox(
        "Batch-Gr√∂√üe f√ºr Simulation",
        options=[1, 10, 100, 500, 1000],
        index=3,  # Standard: 500
        help="Wie viele Zeilen sollen pro Schritt neu 'ins System kommen'?"
    )

    # Steuer-Buttons (Reset, +1 Zeile, +Batch)
    col_b1, col_b2, col_b3 = st.sidebar.columns(3)

    if col_b1.button("‚èÆ Reset"):
        st.session_state.replay_index = 0

    if col_b2.button("‚ûï 1"):
        st.session_state.replay_index = min(
            st.session_state.replay_index + 1,
            n_points - 1
        )

    if col_b3.button(f"+{batch_size}"):
        st.session_state.replay_index = min(
            st.session_state.replay_index + batch_size,
            n_points - 1
        )

    # Optional: Slider zum direkten Springen an eine Stelle
    replay_index = st.sidebar.slider(
        "Direkt springen (Index)",
        min_value=0,
        max_value=n_points - 1,
        value=st.session_state.replay_index,
        step=1,
        help="Bewegt sich von Start der Fahrt (0) bis zum letzten Punkt."
    )

    # Slider-Wert wieder in den Session-State zur√ºckschreiben
    st.session_state.replay_index = replay_index

# Ab hier arbeiten alle Plots & KPIs mit replay_index
replay_index = st.session_state.replay_index
start_idx = max(0, replay_index - window_size)

df_window = df_res.iloc[start_idx:replay_index + 1].copy()
df_until_now = df_res.iloc[:replay_index + 1].copy()

st.caption(
    f"Anzeigezeitraum von Punkt {start_idx} bis {replay_index} "
    f"(von insgesamt {n_points} Messpunkten)."
)



# ------------------------------------------------------------------
# 5. Kennzahlen bis zur aktuellen Replay-Position
# ------------------------------------------------------------------

col_kpi1, col_kpi2, col_kpi3 = st.columns(3)

mae_now = float(np.mean(np.abs(df_until_now["y_true"] - df_until_now["y_pred"])))
rmse_now = float(np.sqrt(np.mean((df_until_now["y_true"] - df_until_now["y_pred"])**2)))
# R¬≤: nur sinnvoll, wenn Varianz vorhanden
if np.var(df_until_now["y_true"]) > 0:
    ss_res = np.sum((df_until_now["y_true"] - df_until_now["y_pred"])**2)
    ss_tot = np.sum((df_until_now["y_true"] - df_until_now["y_true"].mean())**2)
    r2_now = 1 - ss_res / ss_tot
else:
    r2_now = float("nan")

col_kpi1.metric("MAE bis jetzt", f"{mae_now:.4f}")
col_kpi2.metric("RMSE bis jetzt", f"{rmse_now:.4f}")
col_kpi3.metric("R¬≤ bis jetzt", f"{r2_now:.3f}")


# ------------------------------------------------------------------
# 6. Plot 1: Zeitverlauf ‚Äì echte vs. vorhergesagte Dicke
# ------------------------------------------------------------------

st.subheader("Zeitverlauf der Dicke ‚Äì Ist vs. Modellvorhersage")

fig_time = px.line(
    df_window,
    x="time",
    y=["y_true", "y_pred"],
    labels={"value": "Dicke", "time": "Zeit", "variable": "Kurve"},
)

fig_time.update_layout(
    legend_title_text="",
    margin=dict(l=10, r=10, t=40, b=10)
)

st.plotly_chart(fig_time, use_container_width=True)


# ------------------------------------------------------------------
# 7. Plot 2: Echte Werte vs. Vorhersage (Streudiagramm)
# ------------------------------------------------------------------

st.subheader("Streudiagramm ‚Äì Echte Dicke vs. Vorhersage (bis aktuelle Position)")

fig_scatter = px.scatter(
    df_until_now,
    x="y_true",
    y="y_pred",
    labels={"y_true": "Echte Dicke", "y_pred": "Vorhersage"},
)

# Linie x=y hinzuf√ºgen (perfekte Vorhersage)
min_val = min(df_until_now["y_true"].min(), df_until_now["y_pred"].min())
max_val = max(df_until_now["y_true"].max(), df_until_now["y_pred"].max())

fig_scatter.add_shape(
    type="line",
    x0=min_val, y0=min_val,
    x1=max_val, y1=max_val,
    line=dict(dash="dash")
)

fig_scatter.update_layout(
    margin=dict(l=10, r=10, t=40, b=10)
)

st.plotly_chart(fig_scatter, use_container_width=True)


# ------------------------------------------------------------------
# 8. Wichtigste Einflussgr√∂√üen (global + lokal)
# ------------------------------------------------------------------

st.subheader("Wichtigste Einflussgr√∂√üen der KI")

col_fi, col_shap = st.columns(2)

# 8.1 Globale Feature-Importance des Random Forests
with col_fi:
    st.markdown("**Globale Wichtigkeit (Feature Importance des Random Forest)**")

    fi = pd.DataFrame({
        "Feature": feature_names,
        "Importance": model.feature_importances_
    }).sort_values("Importance", ascending=False).head(15)

    fig_fi = px.bar(
        fi,
        x="Importance",
        y="Feature",
        orientation="h",
        labels={"Importance": "Wichtigkeit", "Feature": "Feature"}
    )
    fig_fi.update_layout(
        margin=dict(l=10, r=10, t=40, b=10),
        yaxis=dict(autorange="reversed")
    )
    st.plotly_chart(fig_fi, use_container_width=True)

    st.caption(
        "Diese Darstellung zeigt, welche Eingangsgr√∂√üen das Modell "
        "insgesamt am st√§rksten f√ºr die Dickenvorhersage nutzt."
    )

with col_shap:
    st.markdown("**Lokale Erkl√§rung (SHAP) f√ºr den aktuellen Zeitpunkt**")

    # Keine Argumente -> nichts Hash-Problemtisches mehr
    @st.cache_resource(show_spinner="Initialisiere SHAP-Explainer...")
    def get_explainer():
        return shap.TreeExplainer(model)

    explainer = get_explainer()

    # eine Zeile als DataFrame
    x_row = X_features.iloc[[replay_index]]

    shap_values = explainer.shap_values(x_row)

    # F√ºr Regressionsmodell: shap_values ist ein Array (1, n_features)
    if isinstance(shap_values, list):
        shap_row = shap_values[0][0]
    else:
        shap_row = shap_values[0]

    contrib = pd.Series(shap_row, index=feature_names)
    contrib_abs_sorted = contrib.reindex(contrib.abs().sort_values(ascending=False).index)
    contrib_top = contrib_abs_sorted.head(15)

    contrib_df = pd.DataFrame({
        "Feature": contrib_top.index,
        "Beitrag": contrib_top.values
    })

    fig_shap = px.bar(
        contrib_df,
        x="Beitrag",
        y="Feature",
        orientation="h",
        labels={"Beitrag": "SHAP-Beitrag", "Feature": "Feature"}
    )
    fig_shap.update_layout(
        margin=dict(l=10, r=10, t=40, b=10),
        yaxis=dict(autorange="reversed")
    )

    st.plotly_chart(fig_shap, use_container_width=True)

    st.caption(
        "Positive Werte bedeuten: dieses Feature treibt die Vorhersage **nach oben** "
        "(gr√∂√üere Dicke). Negative Werte: treiben die Vorhersage **nach unten**. "
        "Damit kannst du f√ºr den gew√§hlten Zeitpunkt nachvollziehen, "
        "warum die KI diesen Dickenwert vorgeschlagen hat."
    )

# ------------------------------------------------------------------
# 9. Tabellarische Detailansicht des aktuellen Zeitpunktes
# ------------------------------------------------------------------

st.subheader("Details am aktuellen Replay-Zeitpunkt")

current_true = df_res.iloc[replay_index]["y_true"]
current_pred = df_res.iloc[replay_index]["y_pred"]
current_err = df_res.iloc[replay_index]["error"]

col_c1, col_c2, col_c3 = st.columns(3)
col_c1.metric("Echte Dicke", f"{current_true:.4f}")
col_c2.metric("Vorhersage", f"{current_pred:.4f}")
col_c3.metric("Fehler (Echt - Modell)", f"{current_err:.4f}")

with st.expander("Eingangsfeatures am aktuellen Zeitpunkt anzeigen"):
    st.dataframe(X_features.iloc[[replay_index]].T, use_container_width=True)












import io
import os
import json
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st
import joblib
import plotly.express as px

# ------------------------------------------------------------------
# 0. Grund-Setup
# ------------------------------------------------------------------

st.set_page_config(
    page_title="KM9 KI-Dashboard ‚Äì Assistenzsystem",
    layout="wide"
)

st.title("KM9 KI-Dashboard ‚Äì Assistenzsystem")
st.caption(
    "Empfehlungen f√ºr Maschinenparameter zur Erreichung einer Soll-Dicke "
    "inklusive automatischem Logging f√ºr Nachvollziehbarkeit (EU AI Act)."
)

MODEL_PATH = "rf_dashboard.joblib"
LOG_PATH = "assist_log.csv"


# ------------------------------------------------------------------
# 1. Modell laden
# ------------------------------------------------------------------

@st.cache_resource(show_spinner="Lade Random-Forest-Modell...")
def load_model_bundle(path: str):
    return joblib.load(path)

bundle = load_model_bundle(MODEL_PATH)
model = bundle["model"]
feature_names = bundle["feature_names"]
target_name = bundle["target_name"]
trained_at = bundle.get("trained_at", "unbekannt")
base_metrics = bundle.get("metrics", {})

st.sidebar.subheader("Modell-Info")
st.sidebar.write(f"**Trainiert am:** {trained_at}")
st.sidebar.write(f"**Zielgr√∂√üe:** `{target_name}`")
st.sidebar.write(
    f"**R¬≤ (Trainings-Eval):** {base_metrics.get('r2', float('nan')):.3f}  "
    f"/ **MAE:** {base_metrics.get('mae', float('nan')):.4f}"
)


# ------------------------------------------------------------------
# 2. Soll-Dicke & Prozesszustand-CSV
# ------------------------------------------------------------------

st.sidebar.subheader("Soll-Dicke")

target_thickness = st.sidebar.number_input(
    "Soll-Dicke in mm",
    min_value=0.0,
    max_value=5.0,
    value=1.40,
    step=0.01,
    format="%.2f",
)

st.sidebar.subheader("Prozesszustand (CSV)")

uploaded_file = st.sidebar.file_uploader(
    "CSV mit aktuellem Prozesszustand",
    type=["csv"],
    help="Struktur wie beim Training (gleiche Features)."
)

time_col_guess = st.sidebar.text_input(
    "Zeitspalte (optional)",
    value="timestamp",
    help="Nur f√ºr die Anzeige / Auswahl."
)

if uploaded_file is None:
    st.info("Bitte links im Sidebar eine CSV mit aktuellen Prozessparametern hochladen.")
    st.stop()

# CSV einlesen
try:
    df_proc = pd.read_csv(uploaded_file)
except Exception as e:
    st.error(f"Fehler beim Einlesen der CSV: {e}")
    st.stop()

missing_features = [f for f in feature_names if f not in df_proc.columns]
if missing_features:
    st.error(
        "Folgende Modell-Features fehlen in der CSV:\n\n"
        + ", ".join(missing_features[:40])
    )
    st.stop()

n_points = len(df_proc)
st.markdown(f"**Geladene Prozesspunkte:** {n_points}")

# Zeitspalte vorbereiten (nur f√ºr Auswahl)
if time_col_guess in df_proc.columns:
    df_proc[time_col_guess] = pd.to_datetime(df_proc[time_col_guess], errors="coerce")
    has_time = True
else:
    has_time = False
    df_proc["__idx_time__"] = df_proc.index


# ------------------------------------------------------------------
# 3. Messpunkt / Betriebszustand ausw√§hlen
# ------------------------------------------------------------------

st.sidebar.subheader("Messpunkt ausw√§hlen")

if n_points == 1:
    row_index = 0
    st.sidebar.info("CSV enth√§lt nur einen Messpunkt ‚Äì dieser wird verwendet.")
else:
    if has_time:
        options = df_proc.index.tolist()

        def format_func(idx):
            t = df_proc.loc[idx, time_col_guess]
            return f"{idx} ‚Äì {t}" if pd.notnull(t) else f"{idx}"

        row_index = st.sidebar.selectbox(
            "Messpunkt",
            options=options,
            index=len(options) - 1,
            format_func=format_func
        )
    else:
        row_index = st.sidebar.slider(
            "Messpunkt-Index",
            min_value=0,
            max_value=n_points - 1,
            value=n_points - 1,
            step=1
        )

x_current = df_proc.loc[row_index, feature_names].copy()
x_current_df = x_current.to_frame().T
y_measured = df_proc.loc[row_index, target_name] if target_name in df_proc.columns else np.nan
y_pred_current = float(model.predict(x_current_df)[0])


# ------------------------------------------------------------------
# 4. Regelbare Parameter & physikalische Grenzen (mit Fix)
# ------------------------------------------------------------------

st.sidebar.subheader("Regelbare Maschinenparameter")

suggested_controls = [
    f for f in feature_names
    if any(key in f.lower() for key in ["temp", "temperatur", "druck", "press", "speed", "geschw"])
]

control_features = st.sidebar.multiselect(
    "Regelbare Parameter",
    options=feature_names,
    default=suggested_controls,
    help="Nur diese Gr√∂√üen werden vom System ver√§ndert."
)

if len(control_features) == 0:
    st.warning("Bitte mindestens einen regelbaren Parameter ausw√§hlen.")
    st.stop()

st.sidebar.markdown("**Physikalische Grenzen**")
st.sidebar.caption(
    "Standard = Minimum / Maximum aus der CSV. "
    "Bei konstanten Spalten wird automatisch ein kleiner Bereich um den Wert gelegt."
)

param_bounds = {}
for cf in control_features:
    col_min = float(df_proc[cf].min())
    col_max = float(df_proc[cf].max())
    low, high = sorted([col_min, col_max])

    # *** WICHTIGER FIX ***: wenn low == high (konstante Spalte),
    # k√ºnstlich einen kleinen Bereich darum legen
    if low == high:
        span = max(1.0, abs(low) * 0.1)  # z.B. ¬±10 % oder mindestens ¬±1
        min_slider = low - span
        max_slider = low + span
        default = (low - span / 2, low + span / 2)
    else:
        min_slider = low
        max_slider = high
        default = (low, high)

    bounds = st.sidebar.slider(
        cf,
        min_value=float(min_slider),
        max_value=float(max_slider),
        value=default,
        format="%.4f"
    )
    param_bounds[cf] = bounds

n_candidates = st.sidebar.number_input(
    "Anzahl Kandidaten",
    min_value=50,
    max_value=2000,
    value=300,
    step=50,
    help="Je mehr, desto genauer ‚Äì aber langsamer."
)


# ------------------------------------------------------------------
# 5. Optimierung & Logging
# ------------------------------------------------------------------

def optimize_controls(base_row: pd.Series,
                      control_features: list,
                      param_bounds: dict,
                      target_value: float,
                      n_samples: int = 300):
    rng = np.random.default_rng(42)

    best_row = base_row.copy()
    best_pred = float(
        model.predict(best_row[feature_names].to_frame().T)[0]
    )
    best_error = abs(best_pred - target_value)

    for _ in range(n_samples):
        cand = base_row.copy()
        for cf in control_features:
            low, high = param_bounds[cf]
            cand[cf] = float(rng.uniform(low, high))

        y_pred = float(
            model.predict(cand[feature_names].to_frame().T)[0]
        )
        err = abs(y_pred - target_value)

        if err < best_error:
            best_error = err
            best_pred = y_pred
            best_row = cand

    return best_row, best_pred, best_error


def append_log(entry: dict):
    df_log = pd.DataFrame([entry])
    file_exists = os.path.exists(LOG_PATH)
    if file_exists:
        df_log.to_csv(LOG_PATH, mode="a", header=False, index=False)
    else:
        df_log.to_csv(LOG_PATH, mode="w", header=True, index=False)


calculate = st.sidebar.button("Empfehlung berechnen")

assist_result = None

if calculate:
    best_row, best_pred, best_error = optimize_controls(
        base_row=x_current,
        control_features=control_features,
        param_bounds=param_bounds,
        target_value=target_thickness,
        n_samples=int(n_candidates)
    )

    assist_result = {
        "best_row": best_row,
        "best_pred": best_pred,
        "best_error": best_error,
    }
    st.session_state["assist_result"] = assist_result

    controls_current = {cf: float(x_current[cf]) for cf in control_features}
    controls_recommended = {cf: float(best_row[cf]) for cf in control_features}

    log_entry = {
        "timestamp": datetime.now().isoformat(timespec="seconds"),
        "target_thickness": float(target_thickness),
        "pred_current": float(y_pred_current),
        "pred_recommended": float(best_pred),
        "measured_current": float(y_measured) if not np.isnan(y_measured) else np.nan,
        "controls_current": json.dumps(controls_current),
        "controls_recommended": json.dumps(controls_recommended),
        "source_csv": uploaded_file.name,
        "row_index": int(row_index),
    }

    append_log(log_entry)
    st.sidebar.success(f"Empfehlung berechnet und in `{LOG_PATH}` protokolliert.")

if assist_result is None and "assist_result" in st.session_state:
    assist_result = st.session_state["assist_result"]


# ------------------------------------------------------------------
# 6. Kompaktes Layout: alles Relevante auf einen Blick
# ------------------------------------------------------------------

st.subheader("Aktueller Zustand & Soll-Dicke")

col_top1, col_top2, col_top3 = st.columns(3)

col_top1.metric(
    "Ist-Dicke (Messwert)",
    f"{y_measured:.4f}" if not np.isnan(y_measured) else "n/a"
)
col_top2.metric("Modellprognose (aktuell)", f"{y_pred_current:.4f}")
col_top3.metric("Soll-Dicke", f"{target_thickness:.4f}")

with st.expander("Alle Eingangsgr√∂√üen am aktuellen Messpunkt"):
    st.dataframe(x_current_df.T, use_container_width=True)

st.markdown("---")
st.subheader("Empfehlung der KI f√ºr Maschinenparameter")

if assist_result is None:
    st.info("Noch keine Empfehlung berechnet. Bitte links im Sidebar auf **‚ÄûEmpfehlung berechnen‚Äú** klicken.")
else:
    best_row = assist_result["best_row"]
    best_pred = assist_result["best_pred"]
    best_error = assist_result["best_error"]

    current_error = abs(y_pred_current - target_thickness)

    col_mid1, col_mid2, col_mid3 = st.columns(3)
    col_mid1.metric("Prognose mit Empfehlung", f"{best_pred:.4f}")
    col_mid2.metric("Abweichung zur Soll-Dicke", f"{(best_pred - target_thickness):+.4f}")
    col_mid3.metric("Verbesserung |Fehler|", f"{current_error - best_error:+.4f}")

    # Vergleich nur f√ºr regelbare Parameter
    df_cmp = pd.DataFrame({
        "Parameter": control_features,
        "Aktuell": [float(x_current[cf]) for cf in control_features],
        "Empfehlung": [float(best_row[cf]) for cf in control_features],
    })
    df_cmp["Delta"] = df_cmp["Empfehlung"] - df_cmp["Aktuell"]

    col_bottom_left, col_bottom_right = st.columns([1, 1])

    with col_bottom_left:
        st.markdown("**Regelbare Parameter ‚Äì Tabelle**")
        st.dataframe(df_cmp, use_container_width=True, height=250)

    with col_bottom_right:
        st.markdown("**Empfohlene √Ñnderungen (Œî)**")
        fig_delta = px.bar(
            df_cmp,
            x="Parameter",
            y="Delta",
            labels={"Delta": "Empfohlene √Ñnderung", "Parameter": "Parameter"},
        )
        fig_delta.update_layout(margin=dict(l=10, r=10, t=40, b=10))
        st.plotly_chart(fig_delta, use_container_width=True)

    with st.expander("Vollst√§ndiger empfohlener Eingangsvektor (alle Features)"):
        st.dataframe(best_row[feature_names].to_frame().T, use_container_width=True)


# ------------------------------------------------------------------
# 7. Hinweis zu Transparenz & Logging
# ------------------------------------------------------------------

st.markdown("---")
st.markdown(
    "üîé **Transparenz & Logging:** Jede Berechnung (Soll-Dicke, ausgew√§hlter Messpunkt, "
    "aktuelle Prognose, empfohlene Parameter, neue Prognose) wird automatisch in "
    f"`{LOG_PATH}` protokolliert. So bleiben die Modellentscheidungen nachvollziehbar "
    "und k√∂nnen im Sinne des EU AI Act gepr√ºft werden. Die letzte Entscheidung liegt "
    "immer beim Maschinenf√ºhrer ‚Äì das System gibt nur Empfehlungen."
)
